
*********************************************************
This was run on:
Thu Jan 24 10:59:24 CST 2019
*********************************************************

*********************************************************
Running python train_model.py
JOB 59880 is running on gpu3 
*********************************************************


Reading info from configuration:

Runnning in training setting!

NUM_TRAINING: 2630
NUM_VALIDATION: 240
NUM_EPOCHS: 150
BATCH_SIZE: 2
IMAGE_WIDTH: 320
IMAGE_HEIGHT: 320
IMAGE_DEPTH: 1
CLASS_NAMES: ['Background', 'Beam', 'Not-Beam']
FEATURE_FILE_TRAINING: /data/arbint/input_files/training/feature_w.csv
LABEL_FILE_TRAINING: /data/arbint/input_files/training/label_w.csv
FEATURE_FILE_VALIDATION: /data/arbint/input_files/validation/feature_w.csv
LABEL_FILE_VALIDATION: /data/arbint/input_files/validation/label_w.csv
WEIGHTS: [ 0.4 61.   5. ]

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 320, 320, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 320, 320, 48) 480         input_1[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 320, 320, 48) 0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 320, 320, 48) 192         activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 320, 320, 16) 6928        batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 320, 320, 16) 0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 320, 320, 64) 0           conv2d_1[0][0]                   
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 320, 320, 64) 0           concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 320, 320, 64) 256         activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 320, 320, 16) 9232        batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 320, 320, 16) 0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 320, 320, 80) 0           concatenate_1[0][0]              
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 320, 320, 80) 0           concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 320, 320, 80) 320         activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 320, 320, 16) 11536       batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 320, 320, 16) 0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 320, 320, 96) 0           concatenate_2[0][0]              
                                                                 dropout_3[0][0]                  
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 320, 320, 96) 0           concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 320, 320, 96) 384         activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 320, 320, 16) 13840       batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 320, 320, 16) 0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 320, 320, 112 0           concatenate_3[0][0]              
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 320, 320, 112 0           concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 320, 320, 112 448         activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 160, 160, 112 12656       batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 160, 160, 112 0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 160, 160, 112 0           dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 160, 160, 112 448         activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 160, 160, 16) 16144       batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 160, 160, 16) 0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 160, 160, 128 0           dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 160, 160, 128 0           concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 160, 160, 128 512         activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 160, 160, 16) 18448       batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 160, 160, 16) 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 160, 160, 144 0           concatenate_5[0][0]              
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 160, 160, 144 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 160, 160, 144 576         activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 160, 160, 16) 20752       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 160, 160, 16) 0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 160, 160, 160 0           concatenate_6[0][0]              
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 160, 160, 160 0           concatenate_7[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 160, 160, 160 640         activation_9[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 160, 160, 16) 23056       batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 160, 160, 16) 0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 160, 160, 176 0           concatenate_7[0][0]              
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 160, 160, 176 0           concatenate_8[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 160, 160, 176 704         activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 160, 160, 16) 25360       batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 160, 160, 16) 0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 160, 160, 192 0           concatenate_8[0][0]              
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 160, 160, 192 0           concatenate_9[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 160, 160, 192 768         activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 80, 192)  37056       batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 80, 80, 192)  0           conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 80, 192)  0           dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 80, 192)  768         activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 80, 16)   27664       batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 80, 80, 16)   0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 80, 80, 208)  0           dropout_11[0][0]                 
                                                                 dropout_12[0][0]                 
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 80, 208)  0           concatenate_10[0][0]             
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 80, 208)  832         activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 80, 16)   29968       batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 80, 80, 16)   0           conv2d_14[0][0]                  
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 80, 80, 224)  0           concatenate_10[0][0]             
                                                                 dropout_13[0][0]                 
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 80, 224)  0           concatenate_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 80, 224)  896         activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 80, 16)   32272       batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 80, 80, 16)   0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 80, 80, 240)  0           concatenate_11[0][0]             
                                                                 dropout_14[0][0]                 
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 80, 80, 240)  0           concatenate_12[0][0]             
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 80, 80, 240)  960         activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 80, 80, 16)   34576       batch_normalization_15[0][0]     
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 80, 80, 16)   0           conv2d_16[0][0]                  
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 80, 80, 256)  0           concatenate_12[0][0]             
                                                                 dropout_15[0][0]                 
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 80, 80, 256)  0           concatenate_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 80, 80, 256)  1024        activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 80, 80, 16)   36880       batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 80, 80, 16)   0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 80, 80, 272)  0           concatenate_13[0][0]             
                                                                 dropout_16[0][0]                 
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 80, 80, 272)  0           concatenate_14[0][0]             
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 80, 80, 272)  1088        activation_17[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 80, 80, 16)   39184       batch_normalization_17[0][0]     
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 80, 80, 16)   0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 80, 80, 288)  0           concatenate_14[0][0]             
                                                                 dropout_17[0][0]                 
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 80, 80, 288)  0           concatenate_15[0][0]             
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 80, 80, 288)  1152        activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 80, 80, 16)   41488       batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 80, 80, 16)   0           conv2d_19[0][0]                  
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 80, 80, 304)  0           concatenate_15[0][0]             
                                                                 dropout_18[0][0]                 
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 80, 80, 304)  0           concatenate_16[0][0]             
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 80, 80, 304)  1216        activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 40, 40, 304)  92720       batch_normalization_19[0][0]     
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 40, 40, 304)  0           conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 40, 40, 304)  0           dropout_19[0][0]                 
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 40, 40, 304)  1216        activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 40, 40, 16)   43792       batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 40, 40, 16)   0           conv2d_21[0][0]                  
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 40, 40, 320)  0           dropout_19[0][0]                 
                                                                 dropout_20[0][0]                 
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 40, 40, 320)  0           concatenate_17[0][0]             
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 40, 40, 320)  1280        activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 40, 40, 16)   46096       batch_normalization_21[0][0]     
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 40, 40, 16)   0           conv2d_22[0][0]                  
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 40, 40, 336)  0           concatenate_17[0][0]             
                                                                 dropout_21[0][0]                 
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 40, 40, 336)  0           concatenate_18[0][0]             
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 40, 40, 336)  1344        activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 40, 40, 16)   48400       batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 40, 40, 16)   0           conv2d_23[0][0]                  
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 40, 40, 352)  0           concatenate_18[0][0]             
                                                                 dropout_22[0][0]                 
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 40, 40, 352)  0           concatenate_19[0][0]             
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 40, 40, 352)  1408        activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 40, 40, 16)   50704       batch_normalization_23[0][0]     
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 40, 40, 16)   0           conv2d_24[0][0]                  
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 40, 40, 368)  0           concatenate_19[0][0]             
                                                                 dropout_23[0][0]                 
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 40, 40, 368)  0           concatenate_20[0][0]             
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 40, 40, 368)  1472        activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 40, 40, 16)   53008       batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 40, 40, 16)   0           conv2d_25[0][0]                  
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 40, 40, 384)  0           concatenate_20[0][0]             
                                                                 dropout_24[0][0]                 
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 40, 40, 384)  0           concatenate_21[0][0]             
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 40, 40, 384)  1536        activation_25[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 40, 40, 16)   55312       batch_normalization_25[0][0]     
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 40, 40, 16)   0           conv2d_26[0][0]                  
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 40, 40, 400)  0           concatenate_21[0][0]             
                                                                 dropout_25[0][0]                 
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 40, 40, 400)  0           concatenate_22[0][0]             
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 40, 40, 400)  1600        activation_26[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 40, 40, 16)   57616       batch_normalization_26[0][0]     
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 40, 40, 16)   0           conv2d_27[0][0]                  
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 40, 40, 416)  0           concatenate_22[0][0]             
                                                                 dropout_26[0][0]                 
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 40, 40, 416)  0           concatenate_23[0][0]             
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 40, 40, 416)  1664        activation_27[0][0]              
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 40, 40, 16)   59920       batch_normalization_27[0][0]     
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 40, 40, 16)   0           conv2d_28[0][0]                  
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 40, 40, 432)  0           concatenate_23[0][0]             
                                                                 dropout_27[0][0]                 
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 40, 40, 432)  0           concatenate_24[0][0]             
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 40, 40, 432)  1728        activation_28[0][0]              
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 40, 40, 16)   62224       batch_normalization_28[0][0]     
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 40, 40, 16)   0           conv2d_29[0][0]                  
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 40, 40, 448)  0           concatenate_24[0][0]             
                                                                 dropout_28[0][0]                 
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 40, 40, 448)  0           concatenate_25[0][0]             
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 40, 40, 448)  1792        activation_29[0][0]              
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 40, 40, 16)   64528       batch_normalization_29[0][0]     
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 40, 40, 16)   0           conv2d_30[0][0]                  
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 40, 40, 464)  0           concatenate_25[0][0]             
                                                                 dropout_29[0][0]                 
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 40, 40, 464)  0           concatenate_26[0][0]             
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 40, 40, 464)  1856        activation_30[0][0]              
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 20, 20, 464)  215760      batch_normalization_30[0][0]     
__________________________________________________________________________________________________
dropout_30 (Dropout)            (None, 20, 20, 464)  0           conv2d_31[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 20, 20, 464)  0           dropout_30[0][0]                 
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 20, 20, 464)  1856        activation_31[0][0]              
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 20, 20, 16)   66832       batch_normalization_31[0][0]     
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 20, 20, 16)   0           conv2d_32[0][0]                  
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 20, 20, 480)  0           dropout_30[0][0]                 
                                                                 dropout_31[0][0]                 
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 20, 20, 480)  0           concatenate_27[0][0]             
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 20, 20, 480)  1920        activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 20, 20, 16)   69136       batch_normalization_32[0][0]     
__________________________________________________________________________________________________
dropout_32 (Dropout)            (None, 20, 20, 16)   0           conv2d_33[0][0]                  
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 20, 20, 496)  0           concatenate_27[0][0]             
                                                                 dropout_32[0][0]                 
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 20, 20, 496)  0           concatenate_28[0][0]             
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 20, 20, 496)  1984        activation_33[0][0]              
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 20, 20, 16)   71440       batch_normalization_33[0][0]     
__________________________________________________________________________________________________
dropout_33 (Dropout)            (None, 20, 20, 16)   0           conv2d_34[0][0]                  
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 20, 20, 512)  0           concatenate_28[0][0]             
                                                                 dropout_33[0][0]                 
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 20, 20, 512)  0           concatenate_29[0][0]             
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 20, 20, 512)  2048        activation_34[0][0]              
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 20, 20, 16)   73744       batch_normalization_34[0][0]     
__________________________________________________________________________________________________
dropout_34 (Dropout)            (None, 20, 20, 16)   0           conv2d_35[0][0]                  
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 20, 20, 528)  0           concatenate_29[0][0]             
                                                                 dropout_34[0][0]                 
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 20, 20, 528)  0           concatenate_30[0][0]             
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 20, 20, 528)  2112        activation_35[0][0]              
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 20, 20, 16)   76048       batch_normalization_35[0][0]     
__________________________________________________________________________________________________
dropout_35 (Dropout)            (None, 20, 20, 16)   0           conv2d_36[0][0]                  
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 20, 20, 544)  0           concatenate_30[0][0]             
                                                                 dropout_35[0][0]                 
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 20, 20, 544)  0           concatenate_31[0][0]             
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 20, 20, 544)  2176        activation_36[0][0]              
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 20, 20, 16)   78352       batch_normalization_36[0][0]     
__________________________________________________________________________________________________
dropout_36 (Dropout)            (None, 20, 20, 16)   0           conv2d_37[0][0]                  
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 20, 20, 560)  0           concatenate_31[0][0]             
                                                                 dropout_36[0][0]                 
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 20, 20, 560)  0           concatenate_32[0][0]             
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 20, 20, 560)  2240        activation_37[0][0]              
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 20, 20, 16)   80656       batch_normalization_37[0][0]     
__________________________________________________________________________________________________
dropout_37 (Dropout)            (None, 20, 20, 16)   0           conv2d_38[0][0]                  
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 20, 20, 576)  0           concatenate_32[0][0]             
                                                                 dropout_37[0][0]                 
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 20, 20, 576)  0           concatenate_33[0][0]             
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 20, 20, 576)  2304        activation_38[0][0]              
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 20, 20, 16)   82960       batch_normalization_38[0][0]     
__________________________________________________________________________________________________
dropout_38 (Dropout)            (None, 20, 20, 16)   0           conv2d_39[0][0]                  
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 20, 20, 592)  0           concatenate_33[0][0]             
                                                                 dropout_38[0][0]                 
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 20, 20, 592)  0           concatenate_34[0][0]             
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 20, 20, 592)  2368        activation_39[0][0]              
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 20, 20, 16)   85264       batch_normalization_39[0][0]     
__________________________________________________________________________________________________
dropout_39 (Dropout)            (None, 20, 20, 16)   0           conv2d_40[0][0]                  
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 20, 20, 608)  0           concatenate_34[0][0]             
                                                                 dropout_39[0][0]                 
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 20, 20, 608)  0           concatenate_35[0][0]             
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 20, 20, 608)  2432        activation_40[0][0]              
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 20, 20, 16)   87568       batch_normalization_40[0][0]     
__________________________________________________________________________________________________
dropout_40 (Dropout)            (None, 20, 20, 16)   0           conv2d_41[0][0]                  
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 20, 20, 624)  0           concatenate_35[0][0]             
                                                                 dropout_40[0][0]                 
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 20, 20, 624)  0           concatenate_36[0][0]             
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 20, 20, 624)  2496        activation_41[0][0]              
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 20, 20, 16)   89872       batch_normalization_41[0][0]     
__________________________________________________________________________________________________
dropout_41 (Dropout)            (None, 20, 20, 16)   0           conv2d_42[0][0]                  
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 20, 20, 640)  0           concatenate_36[0][0]             
                                                                 dropout_41[0][0]                 
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 20, 20, 640)  0           concatenate_37[0][0]             
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 20, 20, 640)  2560        activation_42[0][0]              
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 20, 20, 16)   92176       batch_normalization_42[0][0]     
__________________________________________________________________________________________________
dropout_42 (Dropout)            (None, 20, 20, 16)   0           conv2d_43[0][0]                  
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 20, 20, 656)  0           concatenate_37[0][0]             
                                                                 dropout_42[0][0]                 
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 20, 20, 656)  0           concatenate_38[0][0]             
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 20, 20, 656)  2624        activation_43[0][0]              
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 10, 10, 656)  430992      batch_normalization_43[0][0]     
__________________________________________________________________________________________________
dropout_43 (Dropout)            (None, 10, 10, 656)  0           conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 10, 10, 656)  0           dropout_43[0][0]                 
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 10, 10, 656)  2624        activation_44[0][0]              
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 10, 10, 16)   94480       batch_normalization_44[0][0]     
__________________________________________________________________________________________________
dropout_44 (Dropout)            (None, 10, 10, 16)   0           conv2d_45[0][0]                  
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 10, 10, 672)  0           dropout_43[0][0]                 
                                                                 dropout_44[0][0]                 
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 10, 10, 672)  0           concatenate_39[0][0]             
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 10, 10, 672)  2688        activation_45[0][0]              
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 10, 10, 16)   96784       batch_normalization_45[0][0]     
__________________________________________________________________________________________________
dropout_45 (Dropout)            (None, 10, 10, 16)   0           conv2d_46[0][0]                  
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 10, 10, 688)  0           concatenate_39[0][0]             
                                                                 dropout_45[0][0]                 
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 10, 10, 688)  0           concatenate_40[0][0]             
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 10, 10, 688)  2752        activation_46[0][0]              
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 10, 10, 16)   99088       batch_normalization_46[0][0]     
__________________________________________________________________________________________________
dropout_46 (Dropout)            (None, 10, 10, 16)   0           conv2d_47[0][0]                  
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 10, 10, 704)  0           concatenate_40[0][0]             
                                                                 dropout_46[0][0]                 
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 10, 10, 704)  0           concatenate_41[0][0]             
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 10, 10, 704)  2816        activation_47[0][0]              
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 10, 10, 16)   101392      batch_normalization_47[0][0]     
__________________________________________________________________________________________________
dropout_47 (Dropout)            (None, 10, 10, 16)   0           conv2d_48[0][0]                  
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 10, 10, 720)  0           concatenate_41[0][0]             
                                                                 dropout_47[0][0]                 
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 10, 10, 720)  0           concatenate_42[0][0]             
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 10, 10, 720)  2880        activation_48[0][0]              
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 10, 10, 16)   103696      batch_normalization_48[0][0]     
__________________________________________________________________________________________________
dropout_48 (Dropout)            (None, 10, 10, 16)   0           conv2d_49[0][0]                  
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 10, 10, 736)  0           concatenate_42[0][0]             
                                                                 dropout_48[0][0]                 
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 10, 10, 736)  0           concatenate_43[0][0]             
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 10, 10, 736)  2944        activation_49[0][0]              
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 10, 10, 16)   106000      batch_normalization_49[0][0]     
__________________________________________________________________________________________________
dropout_49 (Dropout)            (None, 10, 10, 16)   0           conv2d_50[0][0]                  
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 10, 10, 752)  0           concatenate_43[0][0]             
                                                                 dropout_49[0][0]                 
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 10, 10, 752)  0           concatenate_44[0][0]             
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 10, 10, 752)  3008        activation_50[0][0]              
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 10, 10, 16)   108304      batch_normalization_50[0][0]     
__________________________________________________________________________________________________
dropout_50 (Dropout)            (None, 10, 10, 16)   0           conv2d_51[0][0]                  
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 10, 10, 768)  0           concatenate_44[0][0]             
                                                                 dropout_50[0][0]                 
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 10, 10, 768)  0           concatenate_45[0][0]             
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 10, 10, 768)  3072        activation_51[0][0]              
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 10, 10, 16)   110608      batch_normalization_51[0][0]     
__________________________________________________________________________________________________
dropout_51 (Dropout)            (None, 10, 10, 16)   0           conv2d_52[0][0]                  
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 10, 10, 784)  0           concatenate_45[0][0]             
                                                                 dropout_51[0][0]                 
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 10, 10, 784)  0           concatenate_46[0][0]             
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 10, 10, 784)  3136        activation_52[0][0]              
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 10, 10, 16)   112912      batch_normalization_52[0][0]     
__________________________________________________________________________________________________
dropout_52 (Dropout)            (None, 10, 10, 16)   0           conv2d_53[0][0]                  
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 10, 10, 800)  0           concatenate_46[0][0]             
                                                                 dropout_52[0][0]                 
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 10, 10, 800)  0           concatenate_47[0][0]             
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 10, 10, 800)  3200        activation_53[0][0]              
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 10, 10, 16)   115216      batch_normalization_53[0][0]     
__________________________________________________________________________________________________
dropout_53 (Dropout)            (None, 10, 10, 16)   0           conv2d_54[0][0]                  
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 10, 10, 816)  0           concatenate_47[0][0]             
                                                                 dropout_53[0][0]                 
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 10, 10, 816)  0           concatenate_48[0][0]             
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 10, 10, 816)  3264        activation_54[0][0]              
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 10, 10, 16)   117520      batch_normalization_54[0][0]     
__________________________________________________________________________________________________
dropout_54 (Dropout)            (None, 10, 10, 16)   0           conv2d_55[0][0]                  
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 10, 10, 832)  0           concatenate_48[0][0]             
                                                                 dropout_54[0][0]                 
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 10, 10, 832)  0           concatenate_49[0][0]             
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 10, 10, 832)  3328        activation_55[0][0]              
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 10, 10, 16)   119824      batch_normalization_55[0][0]     
__________________________________________________________________________________________________
dropout_55 (Dropout)            (None, 10, 10, 16)   0           conv2d_56[0][0]                  
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 10, 10, 848)  0           concatenate_49[0][0]             
                                                                 dropout_55[0][0]                 
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 10, 10, 848)  0           concatenate_50[0][0]             
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 10, 10, 848)  3392        activation_56[0][0]              
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 10, 10, 16)   122128      batch_normalization_56[0][0]     
__________________________________________________________________________________________________
dropout_56 (Dropout)            (None, 10, 10, 16)   0           conv2d_57[0][0]                  
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 10, 10, 864)  0           concatenate_50[0][0]             
                                                                 dropout_56[0][0]                 
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 10, 10, 864)  0           concatenate_51[0][0]             
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 10, 10, 864)  3456        activation_57[0][0]              
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 10, 10, 16)   124432      batch_normalization_57[0][0]     
__________________________________________________________________________________________________
dropout_57 (Dropout)            (None, 10, 10, 16)   0           conv2d_58[0][0]                  
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 10, 10, 880)  0           concatenate_51[0][0]             
                                                                 dropout_57[0][0]                 
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 10, 10, 880)  0           concatenate_52[0][0]             
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 10, 10, 880)  3520        activation_58[0][0]              
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 10, 10, 16)   126736      batch_normalization_58[0][0]     
__________________________________________________________________________________________________
dropout_58 (Dropout)            (None, 10, 10, 16)   0           conv2d_59[0][0]                  
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 10, 10, 240)  0           dropout_44[0][0]                 
                                                                 dropout_45[0][0]                 
                                                                 dropout_46[0][0]                 
                                                                 dropout_47[0][0]                 
                                                                 dropout_48[0][0]                 
                                                                 dropout_49[0][0]                 
                                                                 dropout_50[0][0]                 
                                                                 dropout_51[0][0]                 
                                                                 dropout_52[0][0]                 
                                                                 dropout_53[0][0]                 
                                                                 dropout_54[0][0]                 
                                                                 dropout_55[0][0]                 
                                                                 dropout_56[0][0]                 
                                                                 dropout_57[0][0]                 
                                                                 dropout_58[0][0]                 
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 20, 20, 240)  518640      concatenate_54[0][0]             
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 20, 20, 896)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_38[0][0]             
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 20, 20, 896)  0           concatenate_55[0][0]             
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 20, 20, 896)  3584        activation_60[0][0]              
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 20, 20, 16)   129040      batch_normalization_60[0][0]     
__________________________________________________________________________________________________
dropout_60 (Dropout)            (None, 20, 20, 16)   0           conv2d_61[0][0]                  
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 20, 20, 912)  0           concatenate_55[0][0]             
                                                                 dropout_60[0][0]                 
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 20, 20, 912)  0           concatenate_56[0][0]             
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 20, 20, 912)  3648        activation_61[0][0]              
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 20, 20, 16)   131344      batch_normalization_61[0][0]     
__________________________________________________________________________________________________
dropout_61 (Dropout)            (None, 20, 20, 16)   0           conv2d_62[0][0]                  
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 20, 20, 928)  0           concatenate_56[0][0]             
                                                                 dropout_61[0][0]                 
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 20, 20, 928)  0           concatenate_57[0][0]             
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 20, 20, 928)  3712        activation_62[0][0]              
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 20, 20, 16)   133648      batch_normalization_62[0][0]     
__________________________________________________________________________________________________
dropout_62 (Dropout)            (None, 20, 20, 16)   0           conv2d_63[0][0]                  
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 20, 20, 944)  0           concatenate_57[0][0]             
                                                                 dropout_62[0][0]                 
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 20, 20, 944)  0           concatenate_58[0][0]             
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 20, 20, 944)  3776        activation_63[0][0]              
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 20, 20, 16)   135952      batch_normalization_63[0][0]     
__________________________________________________________________________________________________
dropout_63 (Dropout)            (None, 20, 20, 16)   0           conv2d_64[0][0]                  
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 20, 20, 960)  0           concatenate_58[0][0]             
                                                                 dropout_63[0][0]                 
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 20, 20, 960)  0           concatenate_59[0][0]             
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 20, 20, 960)  3840        activation_64[0][0]              
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 20, 20, 16)   138256      batch_normalization_64[0][0]     
__________________________________________________________________________________________________
dropout_64 (Dropout)            (None, 20, 20, 16)   0           conv2d_65[0][0]                  
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 20, 20, 976)  0           concatenate_59[0][0]             
                                                                 dropout_64[0][0]                 
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 20, 20, 976)  0           concatenate_60[0][0]             
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 20, 20, 976)  3904        activation_65[0][0]              
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 20, 20, 16)   140560      batch_normalization_65[0][0]     
__________________________________________________________________________________________________
dropout_65 (Dropout)            (None, 20, 20, 16)   0           conv2d_66[0][0]                  
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 20, 20, 992)  0           concatenate_60[0][0]             
                                                                 dropout_65[0][0]                 
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 20, 20, 992)  0           concatenate_61[0][0]             
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 20, 20, 992)  3968        activation_66[0][0]              
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 20, 20, 16)   142864      batch_normalization_66[0][0]     
__________________________________________________________________________________________________
dropout_66 (Dropout)            (None, 20, 20, 16)   0           conv2d_67[0][0]                  
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 20, 20, 1008) 0           concatenate_61[0][0]             
                                                                 dropout_66[0][0]                 
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 20, 20, 1008) 0           concatenate_62[0][0]             
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 20, 20, 1008) 4032        activation_67[0][0]              
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 20, 20, 16)   145168      batch_normalization_67[0][0]     
__________________________________________________________________________________________________
dropout_67 (Dropout)            (None, 20, 20, 16)   0           conv2d_68[0][0]                  
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 20, 20, 1024) 0           concatenate_62[0][0]             
                                                                 dropout_67[0][0]                 
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 20, 20, 1024) 0           concatenate_63[0][0]             
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 20, 20, 1024) 4096        activation_68[0][0]              
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 20, 20, 16)   147472      batch_normalization_68[0][0]     
__________________________________________________________________________________________________
dropout_68 (Dropout)            (None, 20, 20, 16)   0           conv2d_69[0][0]                  
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 20, 20, 1040) 0           concatenate_63[0][0]             
                                                                 dropout_68[0][0]                 
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 20, 20, 1040) 0           concatenate_64[0][0]             
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 20, 20, 1040) 4160        activation_69[0][0]              
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 20, 20, 16)   149776      batch_normalization_69[0][0]     
__________________________________________________________________________________________________
dropout_69 (Dropout)            (None, 20, 20, 16)   0           conv2d_70[0][0]                  
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 20, 20, 1056) 0           concatenate_64[0][0]             
                                                                 dropout_69[0][0]                 
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 20, 20, 1056) 0           concatenate_65[0][0]             
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 20, 20, 1056) 4224        activation_70[0][0]              
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 20, 20, 16)   152080      batch_normalization_70[0][0]     
__________________________________________________________________________________________________
dropout_70 (Dropout)            (None, 20, 20, 16)   0           conv2d_71[0][0]                  
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 20, 20, 1072) 0           concatenate_65[0][0]             
                                                                 dropout_70[0][0]                 
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 20, 20, 1072) 0           concatenate_66[0][0]             
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 20, 20, 1072) 4288        activation_71[0][0]              
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 20, 20, 16)   154384      batch_normalization_71[0][0]     
__________________________________________________________________________________________________
dropout_71 (Dropout)            (None, 20, 20, 16)   0           conv2d_72[0][0]                  
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 20, 20, 192)  0           dropout_60[0][0]                 
                                                                 dropout_61[0][0]                 
                                                                 dropout_62[0][0]                 
                                                                 dropout_63[0][0]                 
                                                                 dropout_64[0][0]                 
                                                                 dropout_65[0][0]                 
                                                                 dropout_66[0][0]                 
                                                                 dropout_67[0][0]                 
                                                                 dropout_68[0][0]                 
                                                                 dropout_69[0][0]                 
                                                                 dropout_70[0][0]                 
                                                                 dropout_71[0][0]                 
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 40, 40, 192)  331968      concatenate_68[0][0]             
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 40, 40, 656)  0           conv2d_transpose_2[0][0]         
                                                                 concatenate_26[0][0]             
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 40, 40, 656)  0           concatenate_69[0][0]             
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 40, 40, 656)  2624        activation_72[0][0]              
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 40, 40, 16)   94480       batch_normalization_72[0][0]     
__________________________________________________________________________________________________
dropout_72 (Dropout)            (None, 40, 40, 16)   0           conv2d_73[0][0]                  
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 40, 40, 672)  0           concatenate_69[0][0]             
                                                                 dropout_72[0][0]                 
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 40, 40, 672)  0           concatenate_70[0][0]             
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 40, 40, 672)  2688        activation_73[0][0]              
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 40, 40, 16)   96784       batch_normalization_73[0][0]     
__________________________________________________________________________________________________
dropout_73 (Dropout)            (None, 40, 40, 16)   0           conv2d_74[0][0]                  
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 40, 40, 688)  0           concatenate_70[0][0]             
                                                                 dropout_73[0][0]                 
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 40, 40, 688)  0           concatenate_71[0][0]             
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 40, 40, 688)  2752        activation_74[0][0]              
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 40, 40, 16)   99088       batch_normalization_74[0][0]     
__________________________________________________________________________________________________
dropout_74 (Dropout)            (None, 40, 40, 16)   0           conv2d_75[0][0]                  
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 40, 40, 704)  0           concatenate_71[0][0]             
                                                                 dropout_74[0][0]                 
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 40, 40, 704)  0           concatenate_72[0][0]             
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 40, 40, 704)  2816        activation_75[0][0]              
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 40, 40, 16)   101392      batch_normalization_75[0][0]     
__________________________________________________________________________________________________
dropout_75 (Dropout)            (None, 40, 40, 16)   0           conv2d_76[0][0]                  
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 40, 40, 720)  0           concatenate_72[0][0]             
                                                                 dropout_75[0][0]                 
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 40, 40, 720)  0           concatenate_73[0][0]             
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 40, 40, 720)  2880        activation_76[0][0]              
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 40, 40, 16)   103696      batch_normalization_76[0][0]     
__________________________________________________________________________________________________
dropout_76 (Dropout)            (None, 40, 40, 16)   0           conv2d_77[0][0]                  
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 40, 40, 736)  0           concatenate_73[0][0]             
                                                                 dropout_76[0][0]                 
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 40, 40, 736)  0           concatenate_74[0][0]             
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 40, 40, 736)  2944        activation_77[0][0]              
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 40, 40, 16)   106000      batch_normalization_77[0][0]     
__________________________________________________________________________________________________
dropout_77 (Dropout)            (None, 40, 40, 16)   0           conv2d_78[0][0]                  
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 40, 40, 752)  0           concatenate_74[0][0]             
                                                                 dropout_77[0][0]                 
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 40, 40, 752)  0           concatenate_75[0][0]             
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 40, 40, 752)  3008        activation_78[0][0]              
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 40, 40, 16)   108304      batch_normalization_78[0][0]     
__________________________________________________________________________________________________
dropout_78 (Dropout)            (None, 40, 40, 16)   0           conv2d_79[0][0]                  
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 40, 40, 768)  0           concatenate_75[0][0]             
                                                                 dropout_78[0][0]                 
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 40, 40, 768)  0           concatenate_76[0][0]             
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 40, 40, 768)  3072        activation_79[0][0]              
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 40, 40, 16)   110608      batch_normalization_79[0][0]     
__________________________________________________________________________________________________
dropout_79 (Dropout)            (None, 40, 40, 16)   0           conv2d_80[0][0]                  
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 40, 40, 784)  0           concatenate_76[0][0]             
                                                                 dropout_79[0][0]                 
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 40, 40, 784)  0           concatenate_77[0][0]             
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 40, 40, 784)  3136        activation_80[0][0]              
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 40, 40, 16)   112912      batch_normalization_80[0][0]     
__________________________________________________________________________________________________
dropout_80 (Dropout)            (None, 40, 40, 16)   0           conv2d_81[0][0]                  
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 40, 40, 800)  0           concatenate_77[0][0]             
                                                                 dropout_80[0][0]                 
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 40, 40, 800)  0           concatenate_78[0][0]             
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 40, 40, 800)  3200        activation_81[0][0]              
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 40, 40, 16)   115216      batch_normalization_81[0][0]     
__________________________________________________________________________________________________
dropout_81 (Dropout)            (None, 40, 40, 16)   0           conv2d_82[0][0]                  
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 40, 40, 160)  0           dropout_72[0][0]                 
                                                                 dropout_73[0][0]                 
                                                                 dropout_74[0][0]                 
                                                                 dropout_75[0][0]                 
                                                                 dropout_76[0][0]                 
                                                                 dropout_77[0][0]                 
                                                                 dropout_78[0][0]                 
                                                                 dropout_79[0][0]                 
                                                                 dropout_80[0][0]                 
                                                                 dropout_81[0][0]                 
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 80, 80, 160)  230560      concatenate_80[0][0]             
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 80, 80, 464)  0           conv2d_transpose_3[0][0]         
                                                                 concatenate_16[0][0]             
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 80, 80, 464)  0           concatenate_81[0][0]             
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 80, 80, 464)  1856        activation_82[0][0]              
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 80, 80, 16)   66832       batch_normalization_82[0][0]     
__________________________________________________________________________________________________
dropout_82 (Dropout)            (None, 80, 80, 16)   0           conv2d_83[0][0]                  
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 80, 80, 480)  0           concatenate_81[0][0]             
                                                                 dropout_82[0][0]                 
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 80, 80, 480)  0           concatenate_82[0][0]             
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 80, 80, 480)  1920        activation_83[0][0]              
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 80, 80, 16)   69136       batch_normalization_83[0][0]     
__________________________________________________________________________________________________
dropout_83 (Dropout)            (None, 80, 80, 16)   0           conv2d_84[0][0]                  
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 80, 80, 496)  0           concatenate_82[0][0]             
                                                                 dropout_83[0][0]                 
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 80, 80, 496)  0           concatenate_83[0][0]             
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 80, 80, 496)  1984        activation_84[0][0]              
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 80, 80, 16)   71440       batch_normalization_84[0][0]     
__________________________________________________________________________________________________
dropout_84 (Dropout)            (None, 80, 80, 16)   0           conv2d_85[0][0]                  
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 80, 80, 512)  0           concatenate_83[0][0]             
                                                                 dropout_84[0][0]                 
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 80, 80, 512)  0           concatenate_84[0][0]             
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 80, 80, 512)  2048        activation_85[0][0]              
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 80, 80, 16)   73744       batch_normalization_85[0][0]     
__________________________________________________________________________________________________
dropout_85 (Dropout)            (None, 80, 80, 16)   0           conv2d_86[0][0]                  
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 80, 80, 528)  0           concatenate_84[0][0]             
                                                                 dropout_85[0][0]                 
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 80, 80, 528)  0           concatenate_85[0][0]             
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 80, 80, 528)  2112        activation_86[0][0]              
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 80, 80, 16)   76048       batch_normalization_86[0][0]     
__________________________________________________________________________________________________
dropout_86 (Dropout)            (None, 80, 80, 16)   0           conv2d_87[0][0]                  
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 80, 80, 544)  0           concatenate_85[0][0]             
                                                                 dropout_86[0][0]                 
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 80, 80, 544)  0           concatenate_86[0][0]             
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 80, 80, 544)  2176        activation_87[0][0]              
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 80, 80, 16)   78352       batch_normalization_87[0][0]     
__________________________________________________________________________________________________
dropout_87 (Dropout)            (None, 80, 80, 16)   0           conv2d_88[0][0]                  
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 80, 80, 560)  0           concatenate_86[0][0]             
                                                                 dropout_87[0][0]                 
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 80, 80, 560)  0           concatenate_87[0][0]             
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 80, 80, 560)  2240        activation_88[0][0]              
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 80, 80, 16)   80656       batch_normalization_88[0][0]     
__________________________________________________________________________________________________
dropout_88 (Dropout)            (None, 80, 80, 16)   0           conv2d_89[0][0]                  
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 80, 80, 112)  0           dropout_82[0][0]                 
                                                                 dropout_83[0][0]                 
                                                                 dropout_84[0][0]                 
                                                                 dropout_85[0][0]                 
                                                                 dropout_86[0][0]                 
                                                                 dropout_87[0][0]                 
                                                                 dropout_88[0][0]                 
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 160, 160, 112 113008      concatenate_89[0][0]             
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 160, 160, 304 0           conv2d_transpose_4[0][0]         
                                                                 concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 160, 160, 304 0           concatenate_90[0][0]             
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 160, 160, 304 1216        activation_89[0][0]              
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 160, 160, 16) 43792       batch_normalization_89[0][0]     
__________________________________________________________________________________________________
dropout_89 (Dropout)            (None, 160, 160, 16) 0           conv2d_90[0][0]                  
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 160, 160, 320 0           concatenate_90[0][0]             
                                                                 dropout_89[0][0]                 
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 160, 160, 320 0           concatenate_91[0][0]             
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 160, 160, 320 1280        activation_90[0][0]              
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 160, 160, 16) 46096       batch_normalization_90[0][0]     
__________________________________________________________________________________________________
dropout_90 (Dropout)            (None, 160, 160, 16) 0           conv2d_91[0][0]                  
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 160, 160, 336 0           concatenate_91[0][0]             
                                                                 dropout_90[0][0]                 
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 160, 160, 336 0           concatenate_92[0][0]             
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 160, 160, 336 1344        activation_91[0][0]              
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 160, 160, 16) 48400       batch_normalization_91[0][0]     
__________________________________________________________________________________________________
dropout_91 (Dropout)            (None, 160, 160, 16) 0           conv2d_92[0][0]                  
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 160, 160, 352 0           concatenate_92[0][0]             
                                                                 dropout_91[0][0]                 
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 160, 160, 352 0           concatenate_93[0][0]             
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 160, 160, 352 1408        activation_92[0][0]              
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 160, 160, 16) 50704       batch_normalization_92[0][0]     
__________________________________________________________________________________________________
dropout_92 (Dropout)            (None, 160, 160, 16) 0           conv2d_93[0][0]                  
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 160, 160, 368 0           concatenate_93[0][0]             
                                                                 dropout_92[0][0]                 
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 160, 160, 368 0           concatenate_94[0][0]             
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 160, 160, 368 1472        activation_93[0][0]              
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 160, 160, 16) 53008       batch_normalization_93[0][0]     
__________________________________________________________________________________________________
dropout_93 (Dropout)            (None, 160, 160, 16) 0           conv2d_94[0][0]                  
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 160, 160, 80) 0           dropout_89[0][0]                 
                                                                 dropout_90[0][0]                 
                                                                 dropout_91[0][0]                 
                                                                 dropout_92[0][0]                 
                                                                 dropout_93[0][0]                 
__________________________________________________________________________________________________
conv2d_transpose_5 (Conv2DTrans (None, 320, 320, 80) 57680       concatenate_96[0][0]             
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 320, 320, 192 0           conv2d_transpose_5[0][0]         
                                                                 concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 320, 320, 192 0           concatenate_97[0][0]             
__________________________________________________________________________________________________
batch_normalization_94 (BatchNo (None, 320, 320, 192 768         activation_94[0][0]              
__________________________________________________________________________________________________
conv2d_95 (Conv2D)              (None, 320, 320, 16) 27664       batch_normalization_94[0][0]     
__________________________________________________________________________________________________
dropout_94 (Dropout)            (None, 320, 320, 16) 0           conv2d_95[0][0]                  
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 320, 320, 208 0           concatenate_97[0][0]             
                                                                 dropout_94[0][0]                 
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 320, 320, 208 0           concatenate_98[0][0]             
__________________________________________________________________________________________________
batch_normalization_95 (BatchNo (None, 320, 320, 208 832         activation_95[0][0]              
__________________________________________________________________________________________________
conv2d_96 (Conv2D)              (None, 320, 320, 16) 29968       batch_normalization_95[0][0]     
__________________________________________________________________________________________________
dropout_95 (Dropout)            (None, 320, 320, 16) 0           conv2d_96[0][0]                  
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 320, 320, 224 0           concatenate_98[0][0]             
                                                                 dropout_95[0][0]                 
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 320, 320, 224 0           concatenate_99[0][0]             
__________________________________________________________________________________________________
batch_normalization_96 (BatchNo (None, 320, 320, 224 896         activation_96[0][0]              
__________________________________________________________________________________________________
conv2d_97 (Conv2D)              (None, 320, 320, 16) 32272       batch_normalization_96[0][0]     
__________________________________________________________________________________________________
dropout_96 (Dropout)            (None, 320, 320, 16) 0           conv2d_97[0][0]                  
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 320, 320, 240 0           concatenate_99[0][0]             
                                                                 dropout_96[0][0]                 
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 320, 320, 240 0           concatenate_100[0][0]            
__________________________________________________________________________________________________
batch_normalization_97 (BatchNo (None, 320, 320, 240 960         activation_97[0][0]              
__________________________________________________________________________________________________
conv2d_98 (Conv2D)              (None, 320, 320, 16) 34576       batch_normalization_97[0][0]     
__________________________________________________________________________________________________
dropout_97 (Dropout)            (None, 320, 320, 16) 0           conv2d_98[0][0]                  
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 320, 320, 256 0           concatenate_100[0][0]            
                                                                 dropout_97[0][0]                 
__________________________________________________________________________________________________
conv2d_99 (Conv2D)              (None, 320, 320, 3)  771         concatenate_101[0][0]            
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 320, 320, 3)  0           conv2d_99[0][0]                  
==================================================================================================
Total params: 9,422,243
Trainable params: 9,319,171
Non-trainable params: 103,072
__________________________________________________________________________________________________
Epoch 1/150
CSV iteration end for feature. Calling 'break'.
 - 482s - loss: 0.7786 - acc: 0.3332 - mean_iou: 0.4998 - val_loss: 0.7979 - val_acc: 0.2820 - val_mean_iou: 0.5615

Epoch 00001: val_loss improved from inf to 0.79787, saving model to saved_models/model_and_weights.hdf5
CSV iteration end for feature. Calling 'break'.
Epoch 2/150
 - 406s - loss: 0.7298 - acc: 0.3330 - mean_iou: 0.5452 - val_loss: 0.7500 - val_acc: 0.2781 - val_mean_iou: 0.5627

Epoch 00002: val_loss improved from 0.79787 to 0.74997, saving model to saved_models/model_and_weights.hdf5
Epoch 3/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.6839 - acc: 0.3328 - mean_iou: 0.5530 - val_loss: 0.7047 - val_acc: 0.2665 - val_mean_iou: 0.5638

Epoch 00003: val_loss improved from 0.74997 to 0.70472, saving model to saved_models/model_and_weights.hdf5
Epoch 4/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.6406 - acc: 0.3326 - mean_iou: 0.5568 - val_loss: 0.6622 - val_acc: 0.2552 - val_mean_iou: 0.5648

Epoch 00004: val_loss improved from 0.70472 to 0.66221, saving model to saved_models/model_and_weights.hdf5
Epoch 5/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.6000 - acc: 0.3323 - mean_iou: 0.5593 - val_loss: 0.6221 - val_acc: 0.2422 - val_mean_iou: 0.5659

Epoch 00005: val_loss improved from 0.66221 to 0.62210, saving model to saved_models/model_and_weights.hdf5
Epoch 6/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.5619 - acc: 0.3320 - mean_iou: 0.5613 - val_loss: 0.5844 - val_acc: 0.2256 - val_mean_iou: 0.5670

Epoch 00006: val_loss improved from 0.62210 to 0.58440, saving model to saved_models/model_and_weights.hdf5
Epoch 7/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.5261 - acc: 0.3317 - mean_iou: 0.5631 - val_loss: 0.5491 - val_acc: 0.2060 - val_mean_iou: 0.5682

Epoch 00007: val_loss improved from 0.58440 to 0.54909, saving model to saved_models/model_and_weights.hdf5
Epoch 8/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.4927 - acc: 0.3314 - mean_iou: 0.5648 - val_loss: 0.5160 - val_acc: 0.1884 - val_mean_iou: 0.5694

Epoch 00008: val_loss improved from 0.54909 to 0.51596, saving model to saved_models/model_and_weights.hdf5
Epoch 9/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.4615 - acc: 0.3311 - mean_iou: 0.5663 - val_loss: 0.4850 - val_acc: 0.1778 - val_mean_iou: 0.5707

Epoch 00009: val_loss improved from 0.51596 to 0.48500, saving model to saved_models/model_and_weights.hdf5
Epoch 10/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.4325 - acc: 0.3308 - mean_iou: 0.5679 - val_loss: 0.4561 - val_acc: 0.1619 - val_mean_iou: 0.5720

Epoch 00010: val_loss improved from 0.48500 to 0.45609, saving model to saved_models/model_and_weights.hdf5
Epoch 11/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.4054 - acc: 0.3304 - mean_iou: 0.5694 - val_loss: 0.4291 - val_acc: 0.1510 - val_mean_iou: 0.5733

Epoch 00011: val_loss improved from 0.45609 to 0.42907, saving model to saved_models/model_and_weights.hdf5
Epoch 12/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.3801 - acc: 0.3301 - mean_iou: 0.5709 - val_loss: 0.4040 - val_acc: 0.1413 - val_mean_iou: 0.5746

Epoch 00012: val_loss improved from 0.42907 to 0.40397, saving model to saved_models/model_and_weights.hdf5
Epoch 13/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.3567 - acc: 0.3297 - mean_iou: 0.5723 - val_loss: 0.3806 - val_acc: 0.1272 - val_mean_iou: 0.5759

Epoch 00013: val_loss improved from 0.40397 to 0.38059, saving model to saved_models/model_and_weights.hdf5
Epoch 14/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.3350 - acc: 0.3293 - mean_iou: 0.5738 - val_loss: 0.3589 - val_acc: 0.1170 - val_mean_iou: 0.5772

Epoch 00014: val_loss improved from 0.38059 to 0.35895, saving model to saved_models/model_and_weights.hdf5
Epoch 15/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.3148 - acc: 0.3290 - mean_iou: 0.5752 - val_loss: 0.3390 - val_acc: 0.1117 - val_mean_iou: 0.5785

Epoch 00015: val_loss improved from 0.35895 to 0.33899, saving model to saved_models/model_and_weights.hdf5
Epoch 16/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.2961 - acc: 0.3287 - mean_iou: 0.5765 - val_loss: 0.3206 - val_acc: 0.1089 - val_mean_iou: 0.5796

Epoch 00016: val_loss improved from 0.33899 to 0.32056, saving model to saved_models/model_and_weights.hdf5
Epoch 17/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.2787 - acc: 0.3286 - mean_iou: 0.5778 - val_loss: 0.3036 - val_acc: 0.1056 - val_mean_iou: 0.5807

Epoch 00017: val_loss improved from 0.32056 to 0.30355, saving model to saved_models/model_and_weights.hdf5
Epoch 18/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.2627 - acc: 0.3285 - mean_iou: 0.5789 - val_loss: 0.2879 - val_acc: 0.1078 - val_mean_iou: 0.5817

Epoch 00018: val_loss improved from 0.30355 to 0.28789, saving model to saved_models/model_and_weights.hdf5
Epoch 19/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.2477 - acc: 0.3284 - mean_iou: 0.5800 - val_loss: 0.2735 - val_acc: 0.1092 - val_mean_iou: 0.5825

Epoch 00019: val_loss improved from 0.28789 to 0.27353, saving model to saved_models/model_and_weights.hdf5
Epoch 20/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.2338 - acc: 0.3283 - mean_iou: 0.5809 - val_loss: 0.2600 - val_acc: 0.1070 - val_mean_iou: 0.5833

Epoch 00020: val_loss improved from 0.27353 to 0.26003, saving model to saved_models/model_and_weights.hdf5
Epoch 21/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.2209 - acc: 0.3282 - mean_iou: 0.5817 - val_loss: 0.2474 - val_acc: 0.0710 - val_mean_iou: 0.5839

Epoch 00021: val_loss improved from 0.26003 to 0.24740, saving model to saved_models/model_and_weights.hdf5
Epoch 22/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.2089 - acc: 0.3281 - mean_iou: 0.5824 - val_loss: 0.2353 - val_acc: 0.0699 - val_mean_iou: 0.5844

Epoch 00022: val_loss improved from 0.24740 to 0.23527, saving model to saved_models/model_and_weights.hdf5
Epoch 23/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1976 - acc: 0.3280 - mean_iou: 0.5830 - val_loss: 0.2239 - val_acc: 0.0681 - val_mean_iou: 0.5848

Epoch 00023: val_loss improved from 0.23527 to 0.22386, saving model to saved_models/model_and_weights.hdf5
Epoch 24/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.1870 - acc: 0.3279 - mean_iou: 0.5834 - val_loss: 0.2133 - val_acc: 0.0381 - val_mean_iou: 0.5850

Epoch 00024: val_loss improved from 0.22386 to 0.21334, saving model to saved_models/model_and_weights.hdf5
Epoch 25/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1771 - acc: 0.3280 - mean_iou: 0.5836 - val_loss: 0.2035 - val_acc: 0.0073 - val_mean_iou: 0.5851

Epoch 00025: val_loss improved from 0.21334 to 0.20353, saving model to saved_models/model_and_weights.hdf5
Epoch 26/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1678 - acc: 0.3283 - mean_iou: 0.5837 - val_loss: 0.1939 - val_acc: 0.0073 - val_mean_iou: 0.5850

Epoch 00026: val_loss improved from 0.20353 to 0.19391, saving model to saved_models/model_and_weights.hdf5
Epoch 27/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1590 - acc: 0.3288 - mean_iou: 0.5837 - val_loss: 0.1841 - val_acc: 0.0065 - val_mean_iou: 0.5849

Epoch 00027: val_loss improved from 0.19391 to 0.18410, saving model to saved_models/model_and_weights.hdf5
Epoch 28/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.1507 - acc: 0.3298 - mean_iou: 0.5837 - val_loss: 0.1743 - val_acc: 0.0057 - val_mean_iou: 0.5847

Epoch 00028: val_loss improved from 0.18410 to 0.17433, saving model to saved_models/model_and_weights.hdf5
Epoch 29/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1429 - acc: 0.3312 - mean_iou: 0.5836 - val_loss: 0.1651 - val_acc: 0.0064 - val_mean_iou: 0.5845

Epoch 00029: val_loss improved from 0.17433 to 0.16509, saving model to saved_models/model_and_weights.hdf5
Epoch 30/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1355 - acc: 0.3334 - mean_iou: 0.5834 - val_loss: 0.1564 - val_acc: 0.0034 - val_mean_iou: 0.5843

Epoch 00030: val_loss improved from 0.16509 to 0.15636, saving model to saved_models/model_and_weights.hdf5
Epoch 31/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1285 - acc: 0.3363 - mean_iou: 0.5832 - val_loss: 0.1477 - val_acc: 0.0034 - val_mean_iou: 0.5841

Epoch 00031: val_loss improved from 0.15636 to 0.14766, saving model to saved_models/model_and_weights.hdf5
Epoch 32/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1220 - acc: 0.3406 - mean_iou: 0.5830 - val_loss: 0.1386 - val_acc: 0.0020 - val_mean_iou: 0.5839

Epoch 00032: val_loss improved from 0.14766 to 0.13859, saving model to saved_models/model_and_weights.hdf5
Epoch 33/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1158 - acc: 0.3468 - mean_iou: 0.5828 - val_loss: 0.1292 - val_acc: 0.0021 - val_mean_iou: 0.5837

Epoch 00033: val_loss improved from 0.13859 to 0.12917, saving model to saved_models/model_and_weights.hdf5
Epoch 34/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.1099 - acc: 0.3562 - mean_iou: 0.5827 - val_loss: 0.1197 - val_acc: 0.0023 - val_mean_iou: 0.5836

Epoch 00034: val_loss improved from 0.12917 to 0.11974, saving model to saved_models/model_and_weights.hdf5
Epoch 35/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.1044 - acc: 0.3715 - mean_iou: 0.5826 - val_loss: 0.1113 - val_acc: 0.0024 - val_mean_iou: 0.5833

Epoch 00035: val_loss improved from 0.11974 to 0.11128, saving model to saved_models/model_and_weights.hdf5
Epoch 36/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0991 - acc: 0.3951 - mean_iou: 0.5823 - val_loss: 0.1045 - val_acc: 0.0025 - val_mean_iou: 0.5827

Epoch 00036: val_loss improved from 0.11128 to 0.10451, saving model to saved_models/model_and_weights.hdf5
Epoch 37/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0942 - acc: 0.4290 - mean_iou: 0.5817 - val_loss: 0.0994 - val_acc: 0.0026 - val_mean_iou: 0.5816

Epoch 00037: val_loss improved from 0.10451 to 0.09937, saving model to saved_models/model_and_weights.hdf5
Epoch 38/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0895 - acc: 0.4724 - mean_iou: 0.5807 - val_loss: 0.0950 - val_acc: 0.0072 - val_mean_iou: 0.5803

Epoch 00038: val_loss improved from 0.09937 to 0.09498, saving model to saved_models/model_and_weights.hdf5
Epoch 39/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0851 - acc: 0.5242 - mean_iou: 0.5794 - val_loss: 0.0907 - val_acc: 0.0179 - val_mean_iou: 0.5787

Epoch 00039: val_loss improved from 0.09498 to 0.09066, saving model to saved_models/model_and_weights.hdf5
Epoch 40/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0809 - acc: 0.5815 - mean_iou: 0.5779 - val_loss: 0.0862 - val_acc: 0.9896 - val_mean_iou: 0.5772

Epoch 00040: val_loss improved from 0.09066 to 0.08621, saving model to saved_models/model_and_weights.hdf5
Epoch 41/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0769 - acc: 0.6408 - mean_iou: 0.5764 - val_loss: 0.0819 - val_acc: 0.9957 - val_mean_iou: 0.5756

Epoch 00041: val_loss improved from 0.08621 to 0.08186, saving model to saved_models/model_and_weights.hdf5
Epoch 42/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0731 - acc: 0.6991 - mean_iou: 0.5748 - val_loss: 0.0779 - val_acc: 0.9986 - val_mean_iou: 0.5741

Epoch 00042: val_loss improved from 0.08186 to 0.07794, saving model to saved_models/model_and_weights.hdf5
Epoch 43/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0696 - acc: 0.7542 - mean_iou: 0.5734 - val_loss: 0.0744 - val_acc: 0.9985 - val_mean_iou: 0.5727

Epoch 00043: val_loss improved from 0.07794 to 0.07443, saving model to saved_models/model_and_weights.hdf5
Epoch 44/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0662 - acc: 0.8048 - mean_iou: 0.5719 - val_loss: 0.0711 - val_acc: 0.9983 - val_mean_iou: 0.5713

Epoch 00044: val_loss improved from 0.07443 to 0.07111, saving model to saved_models/model_and_weights.hdf5
Epoch 45/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0630 - acc: 0.8499 - mean_iou: 0.5706 - val_loss: 0.0678 - val_acc: 0.9982 - val_mean_iou: 0.5699

Epoch 00045: val_loss improved from 0.07111 to 0.06781, saving model to saved_models/model_and_weights.hdf5
Epoch 46/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0599 - acc: 0.8895 - mean_iou: 0.5693 - val_loss: 0.0646 - val_acc: 0.9981 - val_mean_iou: 0.5686

Epoch 00046: val_loss improved from 0.06781 to 0.06459, saving model to saved_models/model_and_weights.hdf5
Epoch 47/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0570 - acc: 0.9237 - mean_iou: 0.5680 - val_loss: 0.0616 - val_acc: 0.9980 - val_mean_iou: 0.5674

Epoch 00047: val_loss improved from 0.06459 to 0.06155, saving model to saved_models/model_and_weights.hdf5
Epoch 48/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0543 - acc: 0.9523 - mean_iou: 0.5668 - val_loss: 0.0587 - val_acc: 0.9979 - val_mean_iou: 0.5662

Epoch 00048: val_loss improved from 0.06155 to 0.05870, saving model to saved_models/model_and_weights.hdf5
Epoch 49/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0517 - acc: 0.9739 - mean_iou: 0.5656 - val_loss: 0.0560 - val_acc: 0.9979 - val_mean_iou: 0.5650

Epoch 00049: val_loss improved from 0.05870 to 0.05599, saving model to saved_models/model_and_weights.hdf5
Epoch 50/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0492 - acc: 0.9881 - mean_iou: 0.5644 - val_loss: 0.0534 - val_acc: 0.9978 - val_mean_iou: 0.5639

Epoch 00050: val_loss improved from 0.05599 to 0.05339, saving model to saved_models/model_and_weights.hdf5
Epoch 51/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0468 - acc: 0.9955 - mean_iou: 0.5633 - val_loss: 0.0509 - val_acc: 0.9978 - val_mean_iou: 0.5628

Epoch 00051: val_loss improved from 0.05339 to 0.05093, saving model to saved_models/model_and_weights.hdf5
Epoch 52/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0446 - acc: 0.9985 - mean_iou: 0.5623 - val_loss: 0.0486 - val_acc: 0.9978 - val_mean_iou: 0.5618

Epoch 00052: val_loss improved from 0.05093 to 0.04858, saving model to saved_models/model_and_weights.hdf5
Epoch 53/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0425 - acc: 0.9993 - mean_iou: 0.5612 - val_loss: 0.0464 - val_acc: 0.9977 - val_mean_iou: 0.5607

Epoch 00053: val_loss improved from 0.04858 to 0.04636, saving model to saved_models/model_and_weights.hdf5
Epoch 54/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0405 - acc: 0.9994 - mean_iou: 0.5602 - val_loss: 0.0443 - val_acc: 0.9977 - val_mean_iou: 0.5598

Epoch 00054: val_loss improved from 0.04636 to 0.04426, saving model to saved_models/model_and_weights.hdf5
Epoch 55/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0386 - acc: 0.9994 - mean_iou: 0.5593 - val_loss: 0.0423 - val_acc: 0.9977 - val_mean_iou: 0.5588

Epoch 00055: val_loss improved from 0.04426 to 0.04229, saving model to saved_models/model_and_weights.hdf5
Epoch 56/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0368 - acc: 0.9995 - mean_iou: 0.5583 - val_loss: 0.0404 - val_acc: 0.9978 - val_mean_iou: 0.5579

Epoch 00056: val_loss improved from 0.04229 to 0.04044, saving model to saved_models/model_and_weights.hdf5
Epoch 57/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0351 - acc: 0.9995 - mean_iou: 0.5574 - val_loss: 0.0387 - val_acc: 0.9978 - val_mean_iou: 0.5570

Epoch 00057: val_loss improved from 0.04044 to 0.03871, saving model to saved_models/model_and_weights.hdf5
Epoch 58/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0336 - acc: 0.9995 - mean_iou: 0.5566 - val_loss: 0.0371 - val_acc: 0.9979 - val_mean_iou: 0.5561

Epoch 00058: val_loss improved from 0.03871 to 0.03709, saving model to saved_models/model_and_weights.hdf5
Epoch 59/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0320 - acc: 0.9995 - mean_iou: 0.5557 - val_loss: 0.0356 - val_acc: 0.9979 - val_mean_iou: 0.5553

Epoch 00059: val_loss improved from 0.03709 to 0.03558, saving model to saved_models/model_and_weights.hdf5
Epoch 60/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0306 - acc: 0.9995 - mean_iou: 0.5549 - val_loss: 0.0342 - val_acc: 0.9981 - val_mean_iou: 0.5545

Epoch 00060: val_loss improved from 0.03558 to 0.03416, saving model to saved_models/model_and_weights.hdf5
Epoch 61/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0293 - acc: 0.9995 - mean_iou: 0.5541 - val_loss: 0.0328 - val_acc: 0.9982 - val_mean_iou: 0.5537

Epoch 00061: val_loss improved from 0.03416 to 0.03283, saving model to saved_models/model_and_weights.hdf5
Epoch 62/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0280 - acc: 0.9995 - mean_iou: 0.5533 - val_loss: 0.0316 - val_acc: 0.9984 - val_mean_iou: 0.5529

Epoch 00062: val_loss improved from 0.03283 to 0.03159, saving model to saved_models/model_and_weights.hdf5
Epoch 63/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0268 - acc: 0.9995 - mean_iou: 0.5525 - val_loss: 0.0304 - val_acc: 0.9986 - val_mean_iou: 0.5522

Epoch 00063: val_loss improved from 0.03159 to 0.03042, saving model to saved_models/model_and_weights.hdf5
Epoch 64/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0257 - acc: 0.9995 - mean_iou: 0.5518 - val_loss: 0.0293 - val_acc: 0.9989 - val_mean_iou: 0.5515

Epoch 00064: val_loss improved from 0.03042 to 0.02933, saving model to saved_models/model_and_weights.hdf5
Epoch 65/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0247 - acc: 0.9995 - mean_iou: 0.5511 - val_loss: 0.0283 - val_acc: 0.9990 - val_mean_iou: 0.5507

Epoch 00065: val_loss improved from 0.02933 to 0.02830, saving model to saved_models/model_and_weights.hdf5
Epoch 66/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0237 - acc: 0.9996 - mean_iou: 0.5504 - val_loss: 0.0273 - val_acc: 0.9992 - val_mean_iou: 0.5501

Epoch 00066: val_loss improved from 0.02830 to 0.02734, saving model to saved_models/model_and_weights.hdf5
Epoch 67/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0227 - acc: 0.9996 - mean_iou: 0.5497 - val_loss: 0.0264 - val_acc: 0.9992 - val_mean_iou: 0.5494

Epoch 00067: val_loss improved from 0.02734 to 0.02643, saving model to saved_models/model_and_weights.hdf5
Epoch 68/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0218 - acc: 0.9997 - mean_iou: 0.5491 - val_loss: 0.0256 - val_acc: 0.9993 - val_mean_iou: 0.5487

Epoch 00068: val_loss improved from 0.02643 to 0.02558, saving model to saved_models/model_and_weights.hdf5
Epoch 69/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0210 - acc: 0.9997 - mean_iou: 0.5484 - val_loss: 0.0248 - val_acc: 0.9993 - val_mean_iou: 0.5481

Epoch 00069: val_loss improved from 0.02558 to 0.02478, saving model to saved_models/model_and_weights.hdf5
Epoch 70/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0202 - acc: 0.9998 - mean_iou: 0.5478 - val_loss: 0.0240 - val_acc: 0.9993 - val_mean_iou: 0.5475

Epoch 00070: val_loss improved from 0.02478 to 0.02402, saving model to saved_models/model_and_weights.hdf5
Epoch 71/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0195 - acc: 0.9999 - mean_iou: 0.5472 - val_loss: 0.0233 - val_acc: 0.9993 - val_mean_iou: 0.5469

Epoch 00071: val_loss improved from 0.02402 to 0.02331, saving model to saved_models/model_and_weights.hdf5
Epoch 72/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0188 - acc: 0.9999 - mean_iou: 0.5466 - val_loss: 0.0226 - val_acc: 0.9993 - val_mean_iou: 0.5463

Epoch 00072: val_loss improved from 0.02331 to 0.02264, saving model to saved_models/model_and_weights.hdf5
Epoch 73/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0182 - acc: 0.9999 - mean_iou: 0.5460 - val_loss: 0.0220 - val_acc: 0.9993 - val_mean_iou: 0.5457

Epoch 00073: val_loss improved from 0.02264 to 0.02200, saving model to saved_models/model_and_weights.hdf5
Epoch 74/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0175 - acc: 0.9999 - mean_iou: 0.5454 - val_loss: 0.0214 - val_acc: 0.9994 - val_mean_iou: 0.5452

Epoch 00074: val_loss improved from 0.02200 to 0.02139, saving model to saved_models/model_and_weights.hdf5
Epoch 75/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0170 - acc: 0.9999 - mean_iou: 0.5449 - val_loss: 0.0208 - val_acc: 0.9994 - val_mean_iou: 0.5446

Epoch 00075: val_loss improved from 0.02139 to 0.02082, saving model to saved_models/model_and_weights.hdf5
Epoch 76/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0164 - acc: 0.9999 - mean_iou: 0.5444 - val_loss: 0.0203 - val_acc: 0.9994 - val_mean_iou: 0.5441

Epoch 00076: val_loss improved from 0.02082 to 0.02028, saving model to saved_models/model_and_weights.hdf5
Epoch 77/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0159 - acc: 0.9999 - mean_iou: 0.5438 - val_loss: 0.0198 - val_acc: 0.9994 - val_mean_iou: 0.5436

Epoch 00077: val_loss improved from 0.02028 to 0.01976, saving model to saved_models/model_and_weights.hdf5
Epoch 78/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0154 - acc: 0.9999 - mean_iou: 0.5433 - val_loss: 0.0193 - val_acc: 0.9994 - val_mean_iou: 0.5431

Epoch 00078: val_loss improved from 0.01976 to 0.01927, saving model to saved_models/model_and_weights.hdf5
Epoch 79/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0149 - acc: 0.9999 - mean_iou: 0.5428 - val_loss: 0.0188 - val_acc: 0.9994 - val_mean_iou: 0.5426

Epoch 00079: val_loss improved from 0.01927 to 0.01880, saving model to saved_models/model_and_weights.hdf5
Epoch 80/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0144 - acc: 0.9999 - mean_iou: 0.5423 - val_loss: 0.0184 - val_acc: 0.9994 - val_mean_iou: 0.5421

Epoch 00080: val_loss improved from 0.01880 to 0.01836, saving model to saved_models/model_and_weights.hdf5
Epoch 81/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0140 - acc: 0.9999 - mean_iou: 0.5418 - val_loss: 0.0179 - val_acc: 0.9994 - val_mean_iou: 0.5416

Epoch 00081: val_loss improved from 0.01836 to 0.01794, saving model to saved_models/model_and_weights.hdf5
Epoch 82/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0136 - acc: 0.9999 - mean_iou: 0.5414 - val_loss: 0.0175 - val_acc: 0.9994 - val_mean_iou: 0.5411

Epoch 00082: val_loss improved from 0.01794 to 0.01754, saving model to saved_models/model_and_weights.hdf5
Epoch 83/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0132 - acc: 0.9999 - mean_iou: 0.5409 - val_loss: 0.0172 - val_acc: 0.9994 - val_mean_iou: 0.5407

Epoch 00083: val_loss improved from 0.01754 to 0.01716, saving model to saved_models/model_and_weights.hdf5
Epoch 84/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0128 - acc: 0.9999 - mean_iou: 0.5405 - val_loss: 0.0168 - val_acc: 0.9994 - val_mean_iou: 0.5403

Epoch 00084: val_loss improved from 0.01716 to 0.01680, saving model to saved_models/model_and_weights.hdf5
Epoch 85/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0125 - acc: 0.9999 - mean_iou: 0.5400 - val_loss: 0.0165 - val_acc: 0.9995 - val_mean_iou: 0.5398

Epoch 00085: val_loss improved from 0.01680 to 0.01646, saving model to saved_models/model_and_weights.hdf5
Epoch 86/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0121 - acc: 0.9999 - mean_iou: 0.5396 - val_loss: 0.0161 - val_acc: 0.9995 - val_mean_iou: 0.5394

Epoch 00086: val_loss improved from 0.01646 to 0.01613, saving model to saved_models/model_and_weights.hdf5
Epoch 87/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0118 - acc: 0.9999 - mean_iou: 0.5392 - val_loss: 0.0158 - val_acc: 0.9995 - val_mean_iou: 0.5390

Epoch 00087: val_loss improved from 0.01613 to 0.01582, saving model to saved_models/model_and_weights.hdf5
Epoch 88/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0115 - acc: 0.9999 - mean_iou: 0.5388 - val_loss: 0.0155 - val_acc: 0.9995 - val_mean_iou: 0.5386

Epoch 00088: val_loss improved from 0.01582 to 0.01552, saving model to saved_models/model_and_weights.hdf5
Epoch 89/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0112 - acc: 0.9999 - mean_iou: 0.5384 - val_loss: 0.0152 - val_acc: 0.9995 - val_mean_iou: 0.5382

Epoch 00089: val_loss improved from 0.01552 to 0.01523, saving model to saved_models/model_and_weights.hdf5
Epoch 90/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0109 - acc: 0.9999 - mean_iou: 0.5380 - val_loss: 0.0150 - val_acc: 0.9995 - val_mean_iou: 0.5378

Epoch 00090: val_loss improved from 0.01523 to 0.01496, saving model to saved_models/model_and_weights.hdf5
Epoch 91/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0107 - acc: 0.9999 - mean_iou: 0.5376 - val_loss: 0.0147 - val_acc: 0.9995 - val_mean_iou: 0.5374

Epoch 00091: val_loss improved from 0.01496 to 0.01470, saving model to saved_models/model_and_weights.hdf5
Epoch 92/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0104 - acc: 0.9999 - mean_iou: 0.5372 - val_loss: 0.0144 - val_acc: 0.9995 - val_mean_iou: 0.5370

Epoch 00092: val_loss improved from 0.01470 to 0.01445, saving model to saved_models/model_and_weights.hdf5
Epoch 93/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0102 - acc: 0.9999 - mean_iou: 0.5368 - val_loss: 0.0142 - val_acc: 0.9995 - val_mean_iou: 0.5367

Epoch 00093: val_loss improved from 0.01445 to 0.01421, saving model to saved_models/model_and_weights.hdf5
Epoch 94/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0099 - acc: 1.0000 - mean_iou: 0.5365 - val_loss: 0.0140 - val_acc: 0.9995 - val_mean_iou: 0.5363

Epoch 00094: val_loss improved from 0.01421 to 0.01398, saving model to saved_models/model_and_weights.hdf5
Epoch 95/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0097 - acc: 1.0000 - mean_iou: 0.5361 - val_loss: 0.0138 - val_acc: 0.9995 - val_mean_iou: 0.5359

Epoch 00095: val_loss improved from 0.01398 to 0.01376, saving model to saved_models/model_and_weights.hdf5
Epoch 96/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0095 - acc: 1.0000 - mean_iou: 0.5358 - val_loss: 0.0136 - val_acc: 0.9995 - val_mean_iou: 0.5356

Epoch 00096: val_loss improved from 0.01376 to 0.01355, saving model to saved_models/model_and_weights.hdf5
Epoch 97/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0093 - acc: 1.0000 - mean_iou: 0.5354 - val_loss: 0.0134 - val_acc: 0.9995 - val_mean_iou: 0.5353

Epoch 00097: val_loss improved from 0.01355 to 0.01335, saving model to saved_models/model_and_weights.hdf5
Epoch 98/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0091 - acc: 1.0000 - mean_iou: 0.5351 - val_loss: 0.0132 - val_acc: 0.9995 - val_mean_iou: 0.5349

Epoch 00098: val_loss improved from 0.01335 to 0.01316, saving model to saved_models/model_and_weights.hdf5
Epoch 99/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0089 - acc: 1.0000 - mean_iou: 0.5348 - val_loss: 0.0130 - val_acc: 0.9996 - val_mean_iou: 0.5346

Epoch 00099: val_loss improved from 0.01316 to 0.01298, saving model to saved_models/model_and_weights.hdf5
Epoch 100/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0087 - acc: 1.0000 - mean_iou: 0.5344 - val_loss: 0.0128 - val_acc: 0.9996 - val_mean_iou: 0.5343

Epoch 00100: val_loss improved from 0.01298 to 0.01280, saving model to saved_models/model_and_weights.hdf5
Epoch 101/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0086 - acc: 1.0000 - mean_iou: 0.5341 - val_loss: 0.0126 - val_acc: 0.9996 - val_mean_iou: 0.5340

Epoch 00101: val_loss improved from 0.01280 to 0.01264, saving model to saved_models/model_and_weights.hdf5
Epoch 102/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0084 - acc: 1.0000 - mean_iou: 0.5338 - val_loss: 0.0125 - val_acc: 0.9996 - val_mean_iou: 0.5336

Epoch 00102: val_loss improved from 0.01264 to 0.01247, saving model to saved_models/model_and_weights.hdf5
Epoch 103/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0082 - acc: 1.0000 - mean_iou: 0.5335 - val_loss: 0.0123 - val_acc: 0.9996 - val_mean_iou: 0.5333

Epoch 00103: val_loss improved from 0.01247 to 0.01232, saving model to saved_models/model_and_weights.hdf5
Epoch 104/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0081 - acc: 1.0000 - mean_iou: 0.5332 - val_loss: 0.0122 - val_acc: 0.9996 - val_mean_iou: 0.5330

Epoch 00104: val_loss improved from 0.01232 to 0.01217, saving model to saved_models/model_and_weights.hdf5
Epoch 105/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0079 - acc: 1.0000 - mean_iou: 0.5329 - val_loss: 0.0120 - val_acc: 0.9996 - val_mean_iou: 0.5328

Epoch 00105: val_loss improved from 0.01217 to 0.01203, saving model to saved_models/model_and_weights.hdf5
Epoch 106/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0078 - acc: 1.0000 - mean_iou: 0.5326 - val_loss: 0.0119 - val_acc: 0.9996 - val_mean_iou: 0.5325

Epoch 00106: val_loss improved from 0.01203 to 0.01190, saving model to saved_models/model_and_weights.hdf5
Epoch 107/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0077 - acc: 1.0000 - mean_iou: 0.5323 - val_loss: 0.0118 - val_acc: 0.9997 - val_mean_iou: 0.5322

Epoch 00107: val_loss improved from 0.01190 to 0.01177, saving model to saved_models/model_and_weights.hdf5
Epoch 108/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0075 - acc: 1.0000 - mean_iou: 0.5320 - val_loss: 0.0116 - val_acc: 0.9997 - val_mean_iou: 0.5319

Epoch 00108: val_loss improved from 0.01177 to 0.01164, saving model to saved_models/model_and_weights.hdf5
Epoch 109/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0074 - acc: 1.0000 - mean_iou: 0.5318 - val_loss: 0.0115 - val_acc: 0.9997 - val_mean_iou: 0.5316

Epoch 00109: val_loss improved from 0.01164 to 0.01152, saving model to saved_models/model_and_weights.hdf5
Epoch 110/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0073 - acc: 1.0000 - mean_iou: 0.5315 - val_loss: 0.0114 - val_acc: 0.9997 - val_mean_iou: 0.5314

Epoch 00110: val_loss improved from 0.01152 to 0.01140, saving model to saved_models/model_and_weights.hdf5
Epoch 111/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0072 - acc: 1.0000 - mean_iou: 0.5312 - val_loss: 0.0113 - val_acc: 0.9997 - val_mean_iou: 0.5311

Epoch 00111: val_loss improved from 0.01140 to 0.01129, saving model to saved_models/model_and_weights.hdf5
Epoch 112/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0071 - acc: 1.0000 - mean_iou: 0.5310 - val_loss: 0.0112 - val_acc: 0.9997 - val_mean_iou: 0.5308

Epoch 00112: val_loss improved from 0.01129 to 0.01118, saving model to saved_models/model_and_weights.hdf5
Epoch 113/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0070 - acc: 1.0000 - mean_iou: 0.5307 - val_loss: 0.0111 - val_acc: 0.9997 - val_mean_iou: 0.5306

Epoch 00113: val_loss improved from 0.01118 to 0.01108, saving model to saved_models/model_and_weights.hdf5
Epoch 114/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0069 - acc: 1.0000 - mean_iou: 0.5305 - val_loss: 0.0110 - val_acc: 0.9997 - val_mean_iou: 0.5303

Epoch 00114: val_loss improved from 0.01108 to 0.01098, saving model to saved_models/model_and_weights.hdf5
Epoch 115/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0068 - acc: 1.0000 - mean_iou: 0.5302 - val_loss: 0.0109 - val_acc: 0.9997 - val_mean_iou: 0.5301

Epoch 00115: val_loss improved from 0.01098 to 0.01088, saving model to saved_models/model_and_weights.hdf5
Epoch 116/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0067 - acc: 1.0000 - mean_iou: 0.5300 - val_loss: 0.0108 - val_acc: 0.9997 - val_mean_iou: 0.5298

Epoch 00116: val_loss improved from 0.01088 to 0.01078, saving model to saved_models/model_and_weights.hdf5
Epoch 117/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0066 - acc: 1.0000 - mean_iou: 0.5297 - val_loss: 0.0107 - val_acc: 0.9997 - val_mean_iou: 0.5296

Epoch 00117: val_loss improved from 0.01078 to 0.01069, saving model to saved_models/model_and_weights.hdf5
Epoch 118/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0065 - acc: 1.0000 - mean_iou: 0.5295 - val_loss: 0.0106 - val_acc: 0.9997 - val_mean_iou: 0.5294

Epoch 00118: val_loss improved from 0.01069 to 0.01061, saving model to saved_models/model_and_weights.hdf5
Epoch 119/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0064 - acc: 1.0000 - mean_iou: 0.5292 - val_loss: 0.0105 - val_acc: 0.9997 - val_mean_iou: 0.5291

Epoch 00119: val_loss improved from 0.01061 to 0.01052, saving model to saved_models/model_and_weights.hdf5
Epoch 120/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0063 - acc: 1.0000 - mean_iou: 0.5290 - val_loss: 0.0104 - val_acc: 0.9997 - val_mean_iou: 0.5289

Epoch 00120: val_loss improved from 0.01052 to 0.01044, saving model to saved_models/model_and_weights.hdf5
Epoch 121/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0062 - acc: 1.0000 - mean_iou: 0.5288 - val_loss: 0.0104 - val_acc: 0.9997 - val_mean_iou: 0.5287

Epoch 00121: val_loss improved from 0.01044 to 0.01036, saving model to saved_models/model_and_weights.hdf5
Epoch 122/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0062 - acc: 1.0000 - mean_iou: 0.5286 - val_loss: 0.0103 - val_acc: 0.9997 - val_mean_iou: 0.5285

Epoch 00122: val_loss improved from 0.01036 to 0.01028, saving model to saved_models/model_and_weights.hdf5
Epoch 123/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0061 - acc: 1.0000 - mean_iou: 0.5283 - val_loss: 0.0102 - val_acc: 0.9997 - val_mean_iou: 0.5282

Epoch 00123: val_loss improved from 0.01028 to 0.01021, saving model to saved_models/model_and_weights.hdf5
Epoch 124/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0060 - acc: 1.0000 - mean_iou: 0.5281 - val_loss: 0.0101 - val_acc: 0.9997 - val_mean_iou: 0.5280

Epoch 00124: val_loss improved from 0.01021 to 0.01014, saving model to saved_models/model_and_weights.hdf5
Epoch 125/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0059 - acc: 1.0000 - mean_iou: 0.5279 - val_loss: 0.0101 - val_acc: 0.9997 - val_mean_iou: 0.5278

Epoch 00125: val_loss improved from 0.01014 to 0.01007, saving model to saved_models/model_and_weights.hdf5
Epoch 126/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0059 - acc: 1.0000 - mean_iou: 0.5277 - val_loss: 0.0100 - val_acc: 0.9997 - val_mean_iou: 0.5276

Epoch 00126: val_loss improved from 0.01007 to 0.01001, saving model to saved_models/model_and_weights.hdf5
Epoch 127/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0058 - acc: 1.0000 - mean_iou: 0.5275 - val_loss: 0.0099 - val_acc: 0.9997 - val_mean_iou: 0.5274

Epoch 00127: val_loss improved from 0.01001 to 0.00994, saving model to saved_models/model_and_weights.hdf5
Epoch 128/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0058 - acc: 1.0000 - mean_iou: 0.5273 - val_loss: 0.0099 - val_acc: 0.9997 - val_mean_iou: 0.5272

Epoch 00128: val_loss improved from 0.00994 to 0.00988, saving model to saved_models/model_and_weights.hdf5
Epoch 129/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0057 - acc: 1.0000 - mean_iou: 0.5271 - val_loss: 0.0098 - val_acc: 0.9997 - val_mean_iou: 0.5270

Epoch 00129: val_loss improved from 0.00988 to 0.00982, saving model to saved_models/model_and_weights.hdf5
Epoch 130/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0056 - acc: 1.0000 - mean_iou: 0.5269 - val_loss: 0.0098 - val_acc: 0.9997 - val_mean_iou: 0.5268

Epoch 00130: val_loss improved from 0.00982 to 0.00976, saving model to saved_models/model_and_weights.hdf5
Epoch 131/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0056 - acc: 1.0000 - mean_iou: 0.5267 - val_loss: 0.0097 - val_acc: 0.9997 - val_mean_iou: 0.5266

Epoch 00131: val_loss improved from 0.00976 to 0.00971, saving model to saved_models/model_and_weights.hdf5
Epoch 132/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0055 - acc: 1.0000 - mean_iou: 0.5265 - val_loss: 0.0097 - val_acc: 0.9997 - val_mean_iou: 0.5264

Epoch 00132: val_loss improved from 0.00971 to 0.00965, saving model to saved_models/model_and_weights.hdf5
Epoch 133/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0055 - acc: 1.0000 - mean_iou: 0.5263 - val_loss: 0.0096 - val_acc: 0.9997 - val_mean_iou: 0.5262

Epoch 00133: val_loss improved from 0.00965 to 0.00960, saving model to saved_models/model_and_weights.hdf5
Epoch 134/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0054 - acc: 1.0000 - mean_iou: 0.5261 - val_loss: 0.0096 - val_acc: 0.9997 - val_mean_iou: 0.5260

Epoch 00134: val_loss improved from 0.00960 to 0.00955, saving model to saved_models/model_and_weights.hdf5
Epoch 135/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0054 - acc: 1.0000 - mean_iou: 0.5260 - val_loss: 0.0095 - val_acc: 0.9997 - val_mean_iou: 0.5259

Epoch 00135: val_loss improved from 0.00955 to 0.00950, saving model to saved_models/model_and_weights.hdf5
Epoch 136/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0053 - acc: 1.0000 - mean_iou: 0.5258 - val_loss: 0.0095 - val_acc: 0.9997 - val_mean_iou: 0.5257

Epoch 00136: val_loss improved from 0.00950 to 0.00945, saving model to saved_models/model_and_weights.hdf5
Epoch 137/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0053 - acc: 1.0000 - mean_iou: 0.5256 - val_loss: 0.0094 - val_acc: 0.9997 - val_mean_iou: 0.5255

Epoch 00137: val_loss improved from 0.00945 to 0.00940, saving model to saved_models/model_and_weights.hdf5
Epoch 138/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0052 - acc: 1.0000 - mean_iou: 0.5254 - val_loss: 0.0094 - val_acc: 0.9997 - val_mean_iou: 0.5253

Epoch 00138: val_loss improved from 0.00940 to 0.00936, saving model to saved_models/model_and_weights.hdf5
Epoch 139/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0052 - acc: 1.0000 - mean_iou: 0.5252 - val_loss: 0.0093 - val_acc: 0.9997 - val_mean_iou: 0.5252

Epoch 00139: val_loss improved from 0.00936 to 0.00931, saving model to saved_models/model_and_weights.hdf5
Epoch 140/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0051 - acc: 1.0000 - mean_iou: 0.5251 - val_loss: 0.0093 - val_acc: 0.9997 - val_mean_iou: 0.5250

Epoch 00140: val_loss improved from 0.00931 to 0.00927, saving model to saved_models/model_and_weights.hdf5
Epoch 141/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0051 - acc: 1.0000 - mean_iou: 0.5249 - val_loss: 0.0092 - val_acc: 0.9997 - val_mean_iou: 0.5248

Epoch 00141: val_loss improved from 0.00927 to 0.00922, saving model to saved_models/model_and_weights.hdf5
Epoch 142/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0050 - acc: 1.0000 - mean_iou: 0.5247 - val_loss: 0.0092 - val_acc: 0.9997 - val_mean_iou: 0.5247

Epoch 00142: val_loss improved from 0.00922 to 0.00918, saving model to saved_models/model_and_weights.hdf5
Epoch 143/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0050 - acc: 1.0000 - mean_iou: 0.5246 - val_loss: 0.0091 - val_acc: 0.9997 - val_mean_iou: 0.5245

Epoch 00143: val_loss improved from 0.00918 to 0.00914, saving model to saved_models/model_and_weights.hdf5
Epoch 144/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0050 - acc: 1.0000 - mean_iou: 0.5244 - val_loss: 0.0091 - val_acc: 0.9997 - val_mean_iou: 0.5243

Epoch 00144: val_loss improved from 0.00914 to 0.00910, saving model to saved_models/model_and_weights.hdf5
Epoch 145/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0049 - acc: 1.0000 - mean_iou: 0.5242 - val_loss: 0.0091 - val_acc: 0.9997 - val_mean_iou: 0.5242

Epoch 00145: val_loss improved from 0.00910 to 0.00906, saving model to saved_models/model_and_weights.hdf5
Epoch 146/150
CSV iteration end for feature. Calling 'break'.
 - 438s - loss: 0.0049 - acc: 1.0000 - mean_iou: 0.5241 - val_loss: 0.0090 - val_acc: 0.9997 - val_mean_iou: 0.5240

Epoch 00146: val_loss improved from 0.00906 to 0.00902, saving model to saved_models/model_and_weights.hdf5
Epoch 147/150
CSV iteration end for feature. Calling 'break'.
 - 441s - loss: 0.0048 - acc: 1.0000 - mean_iou: 0.5239 - val_loss: 0.0090 - val_acc: 0.9997 - val_mean_iou: 0.5239

Epoch 00147: val_loss improved from 0.00902 to 0.00898, saving model to saved_models/model_and_weights.hdf5
Epoch 148/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0048 - acc: 1.0000 - mean_iou: 0.5238 - val_loss: 0.0089 - val_acc: 0.9997 - val_mean_iou: 0.5237

Epoch 00148: val_loss improved from 0.00898 to 0.00894, saving model to saved_models/model_and_weights.hdf5
Epoch 149/150
CSV iteration end for feature. Calling 'break'.
 - 440s - loss: 0.0048 - acc: 1.0000 - mean_iou: 0.5236 - val_loss: 0.0089 - val_acc: 0.9997 - val_mean_iou: 0.5235

Epoch 00149: val_loss improved from 0.00894 to 0.00891, saving model to saved_models/model_and_weights.hdf5
Epoch 150/150
CSV iteration end for feature. Calling 'break'.
 - 439s - loss: 0.0047 - acc: 1.0000 - mean_iou: 0.5235 - val_loss: 0.0089 - val_acc: 0.9997 - val_mean_iou: 0.5234

Epoch 00150: val_loss improved from 0.00891 to 0.00887, saving model to saved_models/model_and_weights.hdf5
CSV iteration end for feature. Calling 'break'.
*********************************************************
Running python analyze_model.py
JOB 59880 is running on gpu3 
*********************************************************


Running over 5 testing events to generate plots.

Reading info from configuration:
Running over 10 testing events to calculate statistics.

IMAGE_WIDTH: 320
IMAGE_HEIGHT: 320
IMAGE_DEPTH: 1
CLASS_NAMES: ['Background', 'Beam', 'Not-Beam']
FEATURE_FILE_TESTING: /data/arbint/input_files/testing/feature_w.csv
LABEL_FILE_TESTING: /data/arbint/input_files/testing/label_w.csv
WEIGHTS: [ 0.4 61.   5. ]


Number of validation samples IoU evaulated on: 10

IoU for Background is: 49.17%
IoU for Beam is: 1.11%
IoU for Not-Beam is: 10.02%

Mean IoU is: 20.10%

Test accuracy of the model is: 93.54%

Done!

*********************************************************
All done. Exiting
*********************************************************

